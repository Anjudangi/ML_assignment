{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cec5b642-52c9-4fdd-8918-4da816fe1969",
   "metadata": {},
   "source": [
    "Q1. What is Bayes' theorem?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e286ca71-fb97-431b-b857-c98126e9bf42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ans.1 Bayes' Theorem is a fundamental concept in probability theory and statistics, named after the Reverend Thomas Bayes. It describes the probability of an event, based on prior knowledge of conditions that might be related to the event. Bayes' theorem is widely used in various fields such as statistics, machine learning, medicine, and finance to update the probability of a hypothesis as more evidence or information becomes available.\n",
    "\n",
    "# The Formula:\n",
    "# Bayes' Theorem is mathematically expressed as:\n",
    "# P(A∣B)= P(B)P(B∣A)⋅P(A)\n",
    "# (A∣B) is the posterior probability: the probability of event \n",
    "# A occurring given that event \n",
    "# B has occurred.\n",
    "# P(B) is the marginal likelihood: the total probability of event \n",
    "# B occurring under all possible conditions.\n",
    "# Explanation:\n",
    "# Prior Probability (P(A)):\n",
    "\n",
    "# This is the initial degree of belief in the event \n",
    "# A before any additional information is considered. It represents your prior knowledge or assumptions about A.\n",
    "# Likelihood (P(B | A)):\n",
    "\n",
    "# This is the probability of observing the evidence \n",
    "# B, given that \n",
    "# A is true. It measures how well the evidence supports A.\n",
    "# Marginal Likelihood (P(B)):\n",
    "\n",
    "# This is the total probability of observing the evidence \n",
    "# B under all possible scenarios. It is calculated by considering the probability of \n",
    "# B occurring under all possible events, not just A.\n",
    "# Posterior Probability (P(A | B)):\n",
    "\n",
    "# This is the updated probability of event \n",
    "# A after taking into account the new evidence B. It reflects how our belief in \n",
    "# A has changed in light of the new information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35320c85-cdc1-40a1-b101-86c5456e14a6",
   "metadata": {},
   "source": [
    "Q2. What is the formula for Bayes' theorem?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0567647a-20d5-4b33-9875-356a6ee214fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ans.2 The formula for Bayes' Theorem is:\n",
    "\n",
    "# P(A∣B)=P(B∣A)⋅P(A)/p(B)\n",
    "# Where:\n",
    "# P(A∣B) is the posterior probability: the probability of event \n",
    "# A occurring given that event \n",
    "# P(B∣A) is the likelihood: the probability of event \n",
    "# B occurring given that \n",
    "# P(A) is the prior probability: the probability of event \n",
    "# A occurring before considering \n",
    "\n",
    "# P(B) is the marginal likelihood: the total probability of event \n",
    "# B occurring under all possible conditions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a80297d-749b-4164-8a2a-cc03c330277d",
   "metadata": {},
   "source": [
    "Q3. How is Bayes' theorem used in practice?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a06c194-0e9b-4134-aac3-82c750dd62d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ans.3 Bayes' Theorem is widely used in practice across various fields such as statistics, machine learning, medicine, and finance. Here are some practical applications:\n",
    "\n",
    "# 1. Medical Diagnosis:\n",
    "# Scenario: A doctor uses Bayes' Theorem to update the probability that a patient has a certain disease based on the results of a diagnostic test.\n",
    "# Example: Suppose a patient tests positive for a rare disease. Bayes' Theorem can be used to calculate the probability that the patient actually has the disease by considering the prior probability of the disease, the accuracy of the test, and the overall probability of testing positive.\n",
    "# 2. Spam Filtering:\n",
    "# Scenario: Email spam filters use Bayes' Theorem to classify incoming emails as spam or not spam.\n",
    "# Example: The filter calculates the probability that an email is spam given the presence of certain keywords. By updating its beliefs with each new email, the filter improves its accuracy over time.\n",
    "# 3. Machine Learning - Naive Bayes Classifier:\n",
    "# Scenario: In machine learning, the Naive Bayes classifier uses Bayes' Theorem to predict the probability of a class label given a set of features.\n",
    "# Example: In text classification, Bayes' Theorem is used to determine the probability that a given document belongs to a particular category (e.g., sports, politics) based on the words it contains."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a5ed161-a1e6-4df2-b4b4-0ea5824efc14",
   "metadata": {},
   "source": [
    "Q4. What is the relationship between Bayes' theorem and conditional probability?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1cc186d5-16a7-4377-9da5-a8d7c214d7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ans.4 Conditional Probability:\n",
    "# Conditional probability is the probability of an event A occurring given that another event \n",
    "# B has already occurred. It is denoted by P(A∣B) and is calculated using the formula:\n",
    "#     P(A∣B)= P(A∩B)/p(B)\n",
    "    \n",
    " #  Where:\n",
    "# P(A∩B) is the probability that both events \n",
    "# A and B occur.\n",
    "# P(B) is the probability of event B.  \n",
    "\n",
    "# Bayes' Theorem:\n",
    "# Bayes' Theorem provides a way to reverse conditional probabilities. It allows us to calculate the probability of event A given that \n",
    "# B has occurred, using the probability of \n",
    "# B given A and the prior probabilities of A and B.\n",
    "\n",
    "# The relationship between Bayes' Theorem and conditional probability is expressed in the formula:\n",
    "\n",
    "     #  P(A∣B)= P(B∣A)⋅P(A)/p(B)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19db6c3-0a8c-4352-a554-f22bf4fec4a2",
   "metadata": {},
   "source": [
    "Q5. How do you choose which type of Naive Bayes classifier to use for any given problem?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb137aee-3e9d-4ed2-a536-19bb2499cf80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ans.5    1. Gaussian Naive Bayes:\n",
    "Use When: Your features are continuous and you assume that the features follow a normal (Gaussian) distribution.\n",
    "Typical Application:\n",
    "Commonly used in cases where the feature values are real numbers, such as in the Iris dataset (petal length, sepal width, etc.).\n",
    "Example: Predicting whether a student will pass an exam based on continuous features like study hours, attendance percentage, etc.\n",
    "Assumptions: Each feature is normally distributed within each class. If your features do not follow a Gaussian distribution, this might not be the best choice.\n",
    "2. Multinomial Naive Bayes:\n",
    "Use When: Your features are discrete counts, often used in text classification problems where the features represent word counts or term frequencies.\n",
    "Typical Application:\n",
    "Text classification tasks, such as spam detection, sentiment analysis, and document categorization.\n",
    "Example: Classifying emails as spam or not based on the frequency of certain words or phrases.\n",
    "Assumptions: The features represent the number of times an event occurs, such as word counts in a document. It assumes that the probability of a feature is conditioned only on the class label.\n",
    "3. Bernoulli Naive Bayes:\n",
    "Use When: Your features are binary (0 or 1), indicating the presence or absence of a feature. This is also common in text classification but is used when features are binary rather than counts.\n",
    "Typical Application:\n",
    "Binary or boolean features, such as whether a word appears in a document (1 if it appears, 0 if it doesn’t).\n",
    "Example: Classifying documents based on the presence of specific keywords (e.g., \"buy\", \"free\", \"winner\").\n",
    "Assumptions: Each feature is a binary variable, representing the presence or absence of a characteristic in the instance being classified.\n",
    "Summary of How to Choose:\n",
    "Feature Type:\n",
    "\n",
    "If your features are continuous and you believe they follow a normal distribution, go with Gaussian Naive Bayes.\n",
    "If your features are counts or frequencies, especially in text data, Multinomial Naive Bayes is usually the best choice.\n",
    "If your features are binary (indicating presence or absence), Bernoulli Naive Bayes is more appropriate.\n",
    "Data Distribution:\n",
    "\n",
    "Consider the distribution of your data. Gaussian Naive Bayes assumes normal distribution, which might not fit all data types.\n",
    "Multinomial and Bernoulli Naive Bayes make different assumptions about how features behave, so choose based on whether your features are counts or binary.\n",
    "Problem Context:\n",
    "\n",
    "Text classification tasks often benefit from Multinomial or Bernoulli Naive Bayes, depending on whether you are using word counts or binary indicators of word presence.\n",
    "For problems with continuous data, such as predicting outcomes based on measurements, Gaussian Naive Bayes is typically more suitable."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
