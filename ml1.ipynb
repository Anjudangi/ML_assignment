{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dbb0d2df-0015-4ad7-add3-fb5eb36ce0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "296d5b12-9b12-4638-a006-b88c71d41350",
   "metadata": {},
   "source": [
    "Q.1 Define the following with an example:\n",
    "a) Artificial Intelligence\n",
    "b) Machine Learning\n",
    "c) Deep Learning\n",
    "\n",
    "To explain each briefly:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "93a8d573-a2d1-45a2-9406-c28544c7e039",
   "metadata": {},
   "source": [
    "Ans.1  a) Artificial Intelligence (AI)\n",
    "Definition: Artificial Intelligence refers to the simulation of human intelligence in machines that are programmed to think like humans and mimic their actions. AI systems can perform tasks such as recognizing speech, making decisions, translating languages, and solving problems.\n",
    "\n",
    "Example: A popular example of AI is Apple's Siri. Siri can understand voice commands, provide information, make recommendations, and perform actions like sending messages or setting reminders, simulating human-like interaction and intelligence.\n",
    "\n",
    "b) Machine Learning (ML)\n",
    "Definition: Machine Learning is a subset of AI that involves the development of algorithms and statistical models that enable computers to learn and make decisions based on data. ML algorithms improve their performance as they are exposed to more data over time.\n",
    "\n",
    "Example: A common example of machine learning is the recommendation system used by Netflix. Based on the viewing history and preferences of a user, the system learns to suggest movies and TV shows that the user might like.\n",
    "\n",
    "c) Deep Learning\n",
    "Definition: Deep Learning is a subset of machine learning that uses neural networks with many layers (hence \"deep\") to analyze various factors of data. It is particularly effective for large sets of unstructured data such as images, audio, and text.\n",
    "\n",
    "Example: An example of deep learning is Google's DeepMind's AlphaGo, which is a program that learned to play the board game Go at a superhuman level by training on a vast amount of game data and using deep neural networks to make decisions during the game.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9262e585-8f6b-44cb-ab8d-40e66cb3b2de",
   "metadata": {},
   "source": [
    "## Q2- What is supervised machine.? list the example of supervised machine machine learning.?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bda211ac-a0cb-4e3c-a25f-22bab383d99f",
   "metadata": {},
   "source": [
    "ans 2  Explanation:\n",
    "Supervised learning is a type of machine learning where an algorithm is trained on labeled data. The labeled data consists of input-output pairs, where the output is known. The goal is for the algorithm to learn a mapping from inputs to outputs and use this mapping to predict the output for new, unseen inputs.\n",
    "\n",
    "In supervised learning, the training process involves providing the algorithm with a set of training examples that contain both the input features and the corresponding correct output (label). The algorithm uses this information to learn patterns and relationships in the data, which it can then apply to make predictions on new data.\n",
    "\n",
    "Examples of Supervised Learning:\n",
    "\n",
    "Classification:\n",
    "\n",
    "Spam Detection: Email systems classify incoming emails as 'spam' or 'not spam' based on features such as the email's content, sender, and subject line.\n",
    "Image Classification: Identifying objects in images, such as labeling images as containing 'cats', 'dogs', or 'birds'. This is often used in applications like Google Photos.\n",
    "Regression:\n",
    "\n",
    "House Price Prediction: Predicting the price of a house based on features such as location, size, number of bedrooms, and age of the property.\n",
    "Stock Price Prediction: Estimating the future price of a company's stock based on historical stock prices and other financial indicators.\n",
    "Time Series Prediction:\n",
    "\n",
    "Weather Forecasting: Predicting future weather conditions based on historical weather data.\n",
    "Sales Forecasting: Estimating future sales for a company based on past sales data and other relevant factors.\n",
    "Natural Language Processing (NLP):\n",
    "\n",
    "Sentiment Analysis: Determining the sentiment (positive, negative, neutral) of a piece of text, such as customer reviews or social media posts.\n",
    "Language Translation: Translating text from one language to another using paired examples of the same text in different languages.\n",
    "Medical Diagnosis:\n",
    "\n",
    "Disease Detection: Predicting the presence or absence of a disease based on patient data, such as symptoms, medical history, and test results.\n",
    "Image Analysis: Identifying abnormalities in medical images, such as detecting tumors in MRI scans."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef288d8-f18a-4d52-9737-aab4dfc0c60c",
   "metadata": {},
   "source": [
    "Q3- GWhat is unsupervised ml ? List somK examples  of unsupervised ml*.?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f1e7528a-e069-4908-9145-9803cb180169",
   "metadata": {},
   "source": [
    "ans.3 Explanation:\n",
    "Unsupervised learning is a type of machine learning where the algorithm is trained on data without labeled responses. The system tries to learn the patterns and the structure from the data on its own. Unlike supervised learning, there are no explicit output variables to guide the learning process. Instead, the algorithm tries to find hidden structures or relationships within the data.\n",
    "\n",
    "Unsupervised learning is often used for exploratory data analysis to find patterns, group similar data points, and reduce the dimensionality of data.\n",
    "\n",
    "Examples of Unsupervised Learning:\n",
    "\n",
    "Clustering:\n",
    "\n",
    "Customer Segmentation: Grouping customers based on purchasing behavior, demographic information, and other factors to identify distinct segments for targeted marketing.\n",
    "Image Segmentation: Partitioning an image into segments to simplify or change the representation of an image, making it more meaningful and easier to analyze.\n",
    "Dimensionality Reduction:\n",
    "\n",
    "Principal Component Analysis (PCA): Reducing the number of features in a dataset while preserving as much variance as possible. This is useful for visualization and speeding up machine learning algorithms.\n",
    "t-Distributed Stochastic Neighbor Embedding (t-SNE): A technique for reducing the dimensions of data for visualization in a lower-dimensional space, such as 2D or 3D plots.\n",
    "Association Rule Learning:\n",
    "\n",
    "Market Basket Analysis: Finding associations between products purchased together in a transaction. For example, if customers often buy bread and butter together, a store might place these items near each other.\n",
    "Recommendation Systems: Suggesting products or services to users based on the patterns found in user behavior. For example, Netflix recommending movies based on the viewing history of similar users.\n",
    "Anomaly Detection:\n",
    "\n",
    "Fraud Detection: Identifying unusual patterns in transaction data that may indicate fraudulent activity. For instance, unusual spending behavior on a credit card.\n",
    "Network Security: Detecting unusual patterns of network traffic that could signify a security breach or malware activity.\n",
    "Generative Models:\n",
    "\n",
    "Generative Adversarial Networks (GANs): Generating new, synthetic instances of data that mimic the distribution of a given dataset. This is used in applications like creating realistic images or augmenting training data.\n",
    "Autoencoders: Learning efficient codings of input data, which can be used for tasks like image denoising or anomaly detection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b4a3ce-7d61-48fa-b630-eae5c784376c",
   "metadata": {},
   "source": [
    "Q4- What is the difference  between AI, ML, DL, and DS?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "98ce8027-f23c-4024-90f8-ef19f7462a31",
   "metadata": {},
   "source": [
    "ans.4 Artificial Intelligence (AI)\n",
    "Explanation:\n",
    "Artificial Intelligence is a broad field of computer science focused on creating systems that can perform tasks that typically require human intelligence. These tasks include reasoning, learning, problem-solving, perception, language understanding, and more.\n",
    "\n",
    "Scope:\n",
    "AI encompasses various subfields, including machine learning, natural language processing, robotics, and computer vision.\n",
    "\n",
    "Example:\n",
    "A self-driving car, which uses AI to navigate roads, interpret traffic signals, and make driving decisions.\n",
    "\n",
    "Machine Learning (ML)\n",
    "Explanation:\n",
    "Machine Learning is a subset of AI that involves developing algorithms that allow computers to learn from and make predictions or decisions based on data. It focuses on creating models that can improve their performance on tasks with more experience or data.\n",
    "\n",
    "Scope:\n",
    "ML is a specific approach to achieving AI and includes various techniques like supervised learning, unsupervised learning, and reinforcement learning.\n",
    "\n",
    "Example:\n",
    "A spam filter in email services that classifies emails as 'spam' or 'not spam' based on patterns learned from labeled examples.\n",
    "\n",
    "Deep Learning (DL)\n",
    "Explanation:\n",
    "Deep Learning is a specialized subset of Machine Learning that uses neural networks with many layers (hence \"deep\") to analyze various types of data. It excels at handling large volumes of unstructured data, such as images, audio, and text.\n",
    "\n",
    "Scope:\n",
    "DL is a part of ML, focusing on complex neural networks like convolutional neural networks (CNNs) for image processing and recurrent neural networks (RNNs) for sequence data.\n",
    "\n",
    "Example:\n",
    "Image recognition systems that can identify and categorize objects within images, such as recognizing faces in photos on social media platforms.\n",
    "\n",
    "Data Science (DS)\n",
    "Explanation:\n",
    "Data Science is an interdisciplinary field that uses scientific methods, processes, algorithms, and systems to extract knowledge and insights from structured and unstructured data. It combines aspects of statistics, computer science, domain expertise, and data engineering.\n",
    "\n",
    "Scope:\n",
    "DS encompasses a wide range of data-related tasks, including data collection, cleaning, analysis, visualization, and interpretation. It often uses machine learning techniques as tools for analysis and prediction.\n",
    "\n",
    "Example:\n",
    "A data scientist analyzing customer data to identify trends and patterns that can inform business strategies, such as customer segmentation or product recommendation systems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a28057-96eb-49f1-a0a9-70c501c45a98",
   "metadata": {},
   "source": [
    "Q5- What are the main difference  betwwn supervised, unsupervised, and semi-supervised ml?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d6d74531-0498-43ce-b863-1722134d194d",
   "metadata": {},
   "source": [
    "ans.5 Supervised, unsupervised, and semi-supervised learning are three main categories of machine learning, each with distinct characteristics and use cases. Here are the main differences:\n",
    "\n",
    "Supervised Learning\n",
    "Definition:\n",
    "Supervised learning involves training a model on a labeled dataset, meaning that each training example is paired with an output label.\n",
    "\n",
    "Characteristics:\n",
    "\n",
    "Data: Labeled data (input-output pairs).\n",
    "Objective: Learn a mapping from inputs to outputs and make accurate predictions on new, unseen data.\n",
    "Algorithms: Linear regression, logistic regression, decision trees, support vector machines, neural networks.\n",
    "Applications: Classification (e.g., spam detection, image recognition), regression (e.g., predicting house prices, stock prices).\n",
    "Example:\n",
    "Training a model to classify emails as 'spam' or 'not spam' using a dataset where each email is labeled accordingly.\n",
    "\n",
    "Unsupervised Learning\n",
    "Definition:\n",
    "Unsupervised learning involves training a model on a dataset without labeled responses. The model tries to find patterns and structures in the data.\n",
    "\n",
    "Characteristics:\n",
    "\n",
    "Data: Unlabeled data (only input data).\n",
    "Objective: Discover hidden patterns or intrinsic structures within the data.\n",
    "Algorithms: K-means clustering, hierarchical clustering, principal component analysis (PCA), association rules.\n",
    "Applications: Customer segmentation, anomaly detection, market basket analysis, data compression.\n",
    "Example:\n",
    "Clustering customers into different segments based on their purchasing behavior without predefined labels.\n",
    "\n",
    "Semi-Supervised Learning\n",
    "Definition:\n",
    "Semi-supervised learning falls between supervised and unsupervised learning. It uses a combination of a small amount of labeled data and a large amount of unlabeled data to train the model.\n",
    "\n",
    "Characteristics:\n",
    "\n",
    "Data: Both labeled and unlabeled data.\n",
    "Objective: Improve learning accuracy by leveraging the unlabeled data along with the labeled data.\n",
    "Algorithms: Techniques that combine supervised and unsupervised methods, such as semi-supervised SVM, graph-based methods, co-training.\n",
    "Applications: Scenarios where acquiring labeled data is expensive or time-consuming, such as text classification, speech recognition, and bioinformatics.\n",
    "Example:\n",
    "Training a model for text classification with a small set of labeled documents (e.g., labeled as 'sports', 'politics', etc.) and a large set of unlabeled documents to improve the model's performance.\n",
    "\n",
    "Key Differences:\n",
    "Data Requirements:\n",
    "\n",
    "Supervised Learning: Requires a large amount of labeled data.\n",
    "Unsupervised Learning: Does not require labeled data; works with unlabeled data.\n",
    "Semi-Supervised Learning: Requires a small amount of labeled data and a large amount of unlabeled data.\n",
    "Objective:\n",
    "\n",
    "Supervised Learning: Learn a direct mapping from inputs to known outputs.\n",
    "Unsupervised Learning: Discover hidden patterns or structures in the data.\n",
    "Semi-Supervised Learning: Improve learning performance by utilizing both labeled and unlabeled data.\n",
    "Complexity and Use Cases:\n",
    "\n",
    "Supervised Learning: Used when labeled data is abundant and precise predictions are needed.\n",
    "Unsupervised Learning: Used for exploratory data analysis and finding intrinsic patterns in data.\n",
    "Semi-Supervised Learning: Used when labeling data is expensive or impractical, but there is abundant unlabeled data.\n",
    "Summary:\n",
    "Supervised Learning: Relies on labeled data to train models for specific prediction tasks.\n",
    "Unsupervised Learning: Uses unlabeled data to find patterns and structures without specific prediction tasks.\n",
    "Semi-Supervised Learning: Combines small amounts of labeled data with large amounts of unlabeled data to enhance model performance, particularly useful when labeling is costly or time-consuming.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "390fea9d-0d91-410a-89eb-c85956bc78af",
   "metadata": {},
   "source": [
    "Q6- What is train, test and validation split? Explain the importance of each term."
   ]
  },
  {
   "cell_type": "raw",
   "id": "455421d1-e862-41bd-a651-be7b72464832",
   "metadata": {},
   "source": [
    "ans.6 In machine learning, the dataset is often divided into three parts: train set, test set, and validation set. Each of these plays a critical role in building and evaluating a machine learning model.\n",
    "\n",
    "Train, Test, and Validation Split\n",
    "Training Set\n",
    "Validation Set\n",
    "Test Set\n",
    "Training Set\n",
    "Definition:\n",
    "The training set is the portion of the dataset used to train the model. The model learns the underlying patterns, relationships, and features from this data.\n",
    "\n",
    "Importance:\n",
    "\n",
    "Model Training: The model's parameters are adjusted based on this data.\n",
    "Learning Process: The model uses the training data to learn and improve its accuracy.\n",
    "Example:\n",
    "If you have a dataset of 1000 samples, you might use 70% (700 samples) for training.\n",
    "\n",
    "Validation Set\n",
    "Definition:\n",
    "The validation set is used to tune the model's hyperparameters and perform model selection. It helps in evaluating the model's performance during the training process but is not used for updating the model's parameters.\n",
    "\n",
    "Importance:\n",
    "\n",
    "Hyperparameter Tuning: Helps in adjusting the hyperparameters to find the best model.\n",
    "Model Evaluation: Assesses the model's performance during training to avoid overfitting.\n",
    "Early Stopping: Can be used to stop training early if the model's performance on the validation set stops improving.\n",
    "Example:\n",
    "From the remaining 300 samples, you might use 20% (200 samples) for validation.\n",
    "\n",
    "Test Set\n",
    "Definition:\n",
    "The test set is used to evaluate the final model's performance after training is complete. It provides an unbiased assessment of the model's accuracy and generalizability to new, unseen data.\n",
    "\n",
    "Importance:\n",
    "\n",
    "Final Evaluation: Measures how well the model generalizes to new data.\n",
    "Performance Metrics: Provides metrics such as accuracy, precision, recall, and F1-score to assess the model's effectiveness.\n",
    "Avoiding Overfitting: Ensures that the model performs well not just on the training data but also on completely new data.\n",
    "Example:\n",
    "The remaining 10% (100 samples) of the data is used as the test set.\n",
    "\n",
    "Importance of Each Term:\n",
    "Training Set:\n",
    "\n",
    "Core Learning: The model learns from this data.\n",
    "Direct Influence: The quality and size of the training set directly influence the model's ability to learn patterns.\n",
    "Validation Set:\n",
    "\n",
    "Model Tuning: Used for tuning and selecting the best model.\n",
    "Overfitting Prevention: Helps detect overfitting and adjust the model accordingly.\n",
    "Hyperparameter Optimization: Critical for finding the optimal settings that improve model performance.\n",
    "Test Set:\n",
    "\n",
    "Unbiased Evaluation: Provides an unbiased evaluation of the final model.\n",
    "Generalization Check: Ensures the model performs well on new, unseen data.\n",
    "Performance Reporting: Used to report the final performance metrics of the model.\n",
    "Example:\n",
    "Suppose you have a dataset with 10,000 samples for a machine learning project:\n",
    "\n",
    "Training Set (70%): 7,000 samples used to train the model.\n",
    "Validation Set (20%): 2,000 samples used for tuning hyperparameters and model selection.\n",
    "Test Set (10%): 1,000 samples used for final evaluation of the model's performance.\n",
    "Splitting the Data:\n",
    "Data splitting is typically done randomly to ensure that each subset is representative of the overall dataset. Some common methods for splitting data include:\n",
    "\n",
    "Holdout Method: Simple random split into train, validation, and test sets.\n",
    "Cross-Validation: Repeatedly splitting the data into different train and validation sets to ensure robustness, especially useful when the dataset is small."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "283f3d5d-df30-44e9-a720-2436c9c8d20d",
   "metadata": {},
   "source": [
    "Q7- How can unsupervised ml be used in anomaly detection?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6571935d-4f16-44a7-bd04-cf510e9b0f7d",
   "metadata": {},
   "source": [
    "ans.7  Unsupervised learning can be highly effective in anomaly detection, particularly when labeled data is scarce or unavailable. Anomalies, or outliers, are data points that deviate significantly from the majority of the data. Here’s how unsupervised learning can be used in anomaly detection:\n",
    "\n",
    "1. Clustering-Based Methods\n",
    "Clustering algorithms group similar data points together. In the context of anomaly detection, the idea is that normal data points will belong to large clusters, while anomalies will either form small clusters or not belong to any cluster at all.\n",
    "\n",
    "K-Means Clustering: After fitting the K-means algorithm, anomalies can be identified as points that are far from the centroids of their respective clusters.\n",
    "DBSCAN (Density-Based Spatial Clustering of Applications with Noise): This algorithm is particularly suited for anomaly detection because it can identify points in low-density regions as outliers.\n",
    "2. Density-Based Methods\n",
    "These methods estimate the density of data points and identify anomalies as points that lie in low-density regions.\n",
    "\n",
    "Local Outlier Factor (LOF): LOF measures the local density deviation of a data point with respect to its neighbors. Points with significantly lower density than their neighbors are considered anomalies.\n",
    "Isolation Forest: This algorithm isolates observations by randomly selecting a feature and then randomly selecting a split value between the maximum and minimum values of the selected feature. Anomalies are easier to isolate and hence have shorter average path lengths on the trees.\n",
    "3. Autoencoders\n",
    "Autoencoders are neural networks used for learning efficient codings of data. They are particularly effective for anomaly detection in high-dimensional data.\n",
    "\n",
    "Training Phase: The autoencoder is trained to compress the data (encode) and then reconstruct it (decode) as accurately as possible.\n",
    "Detection Phase: When an autoencoder is presented with an anomaly, the reconstruction error (difference between the input and the reconstructed output) will be significantly higher than for normal data points.\n",
    "4. Principal Component Analysis (PCA)\n",
    "PCA reduces the dimensionality of data by projecting it onto a lower-dimensional subspace.\n",
    "\n",
    "Training Phase: PCA identifies the principal components that capture the maximum variance in the data.\n",
    "Detection Phase: Anomalies can be detected by measuring the reconstruction error when data points are projected back from the reduced space to the original space.\n",
    "5. One-Class SVM (Support Vector Machine)\n",
    "One-Class SVM is a variation of the SVM algorithm adapted for unsupervised learning, where it learns the decision boundary around the normal data points.\n",
    "\n",
    "Training Phase: The model is trained on normal data points to define the boundary of the normal region.\n",
    "Detection Phase: Data points that fall outside this boundary are considered anomalies.\n",
    "Steps in Anomaly Detection Using Unsupervised Learning\n",
    "Data Collection: Gather and preprocess the data, handling missing values and scaling features if necessary.\n",
    "Model Selection: Choose an appropriate unsupervised learning method based on the nature and dimensionality of the data.\n",
    "Training: Fit the model to the data to learn the normal patterns.\n",
    "Anomaly Scoring: Use the model to assign an anomaly score to each data point.\n",
    "Thresholding: Determine a threshold for the anomaly score above which points are considered anomalies.\n",
    "Evaluation: Validate the results using known anomalies if available or use domain expertise to evaluate the model performance.\n",
    "Unsupervised learning methods for anomaly detection are powerful tools, especially in scenarios where labeled data is not available. They rely on the assumption that anomalies differ significantly from the normal data, which allows these methods to effectively identify outliers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33820fc2-1bc0-4916-8c32-3343422b9ff8",
   "metadata": {},
   "source": [
    "Q8- List down some commonly used supervised ml algorithms and unsupervied learning\n",
    "algorithms."
   ]
  },
  {
   "cell_type": "raw",
   "id": "556b5aa1-c9eb-464f-a081-7fd1859b35ab",
   "metadata": {},
   "source": [
    "ans.8 Sure! Here's a list of commonly used supervised and unsupervised learning algorithms:\n",
    "\n",
    "Supervised Learning Algorithms:\n",
    "Linear Regression: A regression algorithm that finds a linear relationship between input features and a continuous target variable.\n",
    "\n",
    "Logistic Regression: Used for binary classification problems, logistic regression estimates probabilities using a logistic function.\n",
    "\n",
    "Decision Trees: Tree-like models where each node represents a decision based on input features, used for both classification and regression tasks.\n",
    "\n",
    "Random Forest: An ensemble method that builds multiple decision trees and averages their predictions to improve accuracy and control overfitting.\n",
    "\n",
    "Support Vector Machines (SVM): A powerful algorithm for both classification and regression tasks, which finds a hyperplane that best separates classes.\n",
    "\n",
    "Naive Bayes: A probabilistic classifier based on Bayes' theorem with strong independence assumptions between features.\n",
    "\n",
    "Neural Networks: Deep learning models composed of multiple layers of interconnected neurons, capable of learning complex patterns.\n",
    "\n",
    "Gradient Boosting Machines (GBM): Boosting ensemble technique where each new model fits to improve the shortcomings of the combined model.\n",
    "\n",
    "Unsupervised Learning Algorithms:\n",
    "K-Means Clustering: Partitioning data into clusters where each observation belongs to the cluster with the nearest mean, serving as a prototype of the cluster.\n",
    "\n",
    "Hierarchical Clustering: Builds a hierarchy of clusters either top-down (divisive) or bottom-up (agglomerative) based on the distance between data points.\n",
    "\n",
    "DBSCAN (Density-Based Spatial Clustering of Applications with Noise): Clustering algorithm that groups together points that are closely packed together and marks points in low-density regions as outliers.\n",
    "\n",
    "Principal Component Analysis (PCA): Technique for reducing the dimensionality of data by projecting it onto a lower-dimensional space while retaining most of its variance.\n",
    "\n",
    "Autoencoders: Neural network models designed to learn efficient representations (encodings) of data by compressing and then reconstructing it.\n",
    "\n",
    "Isolation Forest: An ensemble method for anomaly detection that isolates anomalies by randomly selecting features and splitting points between normal and anomalous.\n",
    "\n",
    "Local Outlier Factor (LOF): An algorithm for outlier detection that computes the local density deviation of a data point relative to its neighbors.\n",
    "\n",
    "One-Class SVM: SVM variant that learns a decision boundary around normal instances, useful for anomaly detection when only normal data is available for training.\n",
    "\n",
    "These algorithms cover a broad spectrum of techniques used in machine learning, each suited to different types of tasks and data characteristics, whether supervised for labeled data or unsupervised for exploring patterns and anomalies in data without prior labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7d6a35-c5f9-44c8-9a02-ff68063ca638",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
